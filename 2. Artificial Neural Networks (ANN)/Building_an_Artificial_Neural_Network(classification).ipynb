{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5pdfkELO-B4B"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pOds9zfkAuHM",
    "outputId": "6b739b7e-1029-4060-db59-317ba298fc32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ozQ7pMhYAwkD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNKcbM8eD9u5"
   },
   "source": [
    "# <mark>`Data Preprocessing`</mark>\n",
    "\n",
    "**<mark>`Loading data`</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PqVmLeuYFGG4"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_xbjkKEFP1w"
   },
   "source": [
    "<mark>**`Normalizing the images`**</mark>\n",
    "\n",
    "we divide each and every pixel of the image in the trianing and testing sets by the maximum number of pixels (255)\r\n",
    "In this way each pixel will be in the range[0,1], Ny normalizing images we make sure that our model (ANN) trains faster\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M7XrSfwkFji3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_BSPws-DIeu3"
   },
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzG9qtn5S6cH",
    "outputId": "c5bf0cef-745e-4f4c-a60c-0259dfde614d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GIl5uFyIjfG"
   },
   "source": [
    "## <mark>`Reshaping the data`</mark>\n",
    "\n",
    "we are working on building a fully connected neural network, for that we reshape the training and test into vector form..\r\n",
    "\n",
    "vector ---> flate \n",
    "\n",
    "\n",
    "\n",
    "tensor ---> X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l4nTfQJYIm_H"
   },
   "outputs": [],
   "source": [
    "# you can see that our datasets are 28*28 dimensions..\n",
    "# we will reshape and flatten the images of dataset\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "\n",
    "# you can see that our images is 28*28 so we multiply X-axis and y-axis of the images to flatten the images of dataset\n",
    "# and -1 means all images... meaning convert nth number of image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOQwcovGSyGZ",
    "outputId": "917b48c6-37c5-4a4a-d96b-acce0cb3f221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D6azateDT4ru"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6BEjcWbT_Ad",
    "outputId": "9feb029c-d665-4e13-f4c5-90e7b581b607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAXk23bvTk8u"
   },
   "source": [
    "**See in the above cells that our all images of the dataset are now flatten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQK0TQoyWhuF"
   },
   "source": [
    "# <mark>`Building Artificial Neural Network`</mark>\n",
    "**Defining the Model**\n",
    "\n",
    "Simply define an object of the Sequential model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>`ANN architecture`</mark>\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Facundo-Bre/publication/321259051/figure/fig1/AS:614329250496529@1523478915726/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o.png\">\n",
    "\n",
    "\n",
    "**<mark>`Activation Functions`</mark>**\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png\">\n",
    "\n",
    "**<mark>`Dropout`<mark>**\n",
    "    \n",
    "    \n",
    "<img src=\"https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0408.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XGs5qwMSWpgt"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OA8galWSXGKF"
   },
   "source": [
    "**Adding a fully-connected Hidden layer**\n",
    "layer hyperparameter:\r\n",
    "  * number of neurons/units : 128\n",
    "  * activation function : ReLU\n",
    "  * input_shape: (784, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Tus_OAvDXoQE"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_uniform', input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Relu` effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q3JyNPRRhY9"
   },
   "source": [
    "**Adding PReLU Acitivation function to the archetecture of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IrWoDP94Q31l"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.PReLU(alpha_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBLyZ7uMTHWT"
   },
   "source": [
    "**with tanh activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KZ7QTkeJOqyW"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=64, activation='tanh', input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lpkApvbWTFnz"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=64, activation='relu',  input_shape=(784, ))) \n",
    "# # we can initialize weight by kernel_initializer='he_uniform',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTbDdbuvVGC0"
   },
   "source": [
    "**Defining Leaky_relu activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "73PdUMsQTod7"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# leaky_relu = LeakyReLU(alpha=0.01)\r\n",
    "# model.add(tf.keras.layers.Dense(units=64, activation=leaky_relu, input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hTopgFuOPQUI"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=32, activation='relu',  input_shape=(784, )))\n",
    "\n",
    "# # we can also initialize weight by kernel_initializer='he_uniform',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-DF6G0sX8zM"
   },
   "source": [
    "**Adding a Second layer with Dropout**\n",
    ">Dropout is a Regularization technique where we randomly set neurons in a layer to zero. That way while training those neurons won't be uploaded. Because some percentage od neurons won't be updated the whole training process is long and we have less chance for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PsmAw_vJY9Vb"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C1WZf36ZyZr"
   },
   "source": [
    "**Adding the output layer**\n",
    "  * units number of classes (10 in the Fashion MNIST dataset)\n",
    "  * activation: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6eb_RjDHaL9B"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Softmax` takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZznSG0egTTra"
   },
   "source": [
    "**Output layer with Sigmoid activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uEz1PQ7CS4YE"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "incyYb3raYrq"
   },
   "source": [
    "**Compiling the model**\n",
    "  * Optimizer: Adam\r\n",
    "  * Loss : Sparse softmax (categorical) crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up intilial_learning_rate, total_steps/decay_steps, decay_rate/warmup_learning_rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.0001)\n",
    "\n",
    "## decay_steps == warmup_steps\n",
    "## decay_rate == decay_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiHFXsqXXUMo"
   },
   "source": [
    "**Setting up Learning rate of optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0z0ShBgJa5bR"
   },
   "outputs": [],
   "source": [
    "# defining Learning rate for adam optimizer\n",
    "\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,  loss='sparse_categorical_crossentropy', metrics='sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb9UWX-bZRPn"
   },
   "source": [
    "**Trying SGD (Stochostic Gradient Descent) optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pbOdJRWhZZeG"
   },
   "outputs": [],
   "source": [
    "# Defining SGD Optimizer and assigining Learning_rate\n",
    "# from keras.optimizers import SGD\r\n",
    "\n",
    "# # decay=0.01\n",
    "# # With learning rate decay, the learning rate is calculated each update (e.g. end of each mini-batch) as follows:\n",
    "# # lrate = initial_lrate * (1 / (1 + decay * iteration))\n",
    "\n",
    "# opt = SGD(lr=0.01, momentum=0.9, decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtnL9xbhjo_s"
   },
   "source": [
    "**Checking the Artichecture of our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZPpe10cjlt-",
    "outputId": "e18521a3-784d-4169-f61c-7bd7ca94f83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Mo9QMXjnXk"
   },
   "source": [
    "**<mark>`Train the model`</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_ufEr1bkeCz",
    "outputId": "f3d1628a-319e-4fcd-bd6d-27b43f8f4d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 892us/step - loss: 0.6696 - sparse_categorical_accuracy: 0.7644\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.4083 - sparse_categorical_accuracy: 0.8523\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 816us/step - loss: 0.3683 - sparse_categorical_accuracy: 0.8655\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.3421 - sparse_categorical_accuracy: 0.8742\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 2s 893us/step - loss: 0.3278 - sparse_categorical_accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.3148 - sparse_categorical_accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 809us/step - loss: 0.3029 - sparse_categorical_accuracy: 0.8878\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8888\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2911 - sparse_categorical_accuracy: 0.8915\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.2801 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2770 - sparse_categorical_accuracy: 0.8976\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2756 - sparse_categorical_accuracy: 0.8973\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.2602 - sparse_categorical_accuracy: 0.9005\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.2564 - sparse_categorical_accuracy: 0.9038\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.2496 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.2500 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.2431 - sparse_categorical_accuracy: 0.9066\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.2405 - sparse_categorical_accuracy: 0.9085\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 862us/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9133\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 827us/step - loss: 0.2369 - sparse_categorical_accuracy: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5e3aa7700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0mKBg9WleOi",
    "outputId": "3213625b-a376-4cd7-d801-b139138eb19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGWJSe3kl7SS"
   },
   "source": [
    "**Model evaluation and prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91sX9jNNmQ36",
    "outputId": "50c48d79-9fd2-4c68-d943-9202a7c16c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 797us/step - loss: 0.3348 - sparse_categorical_accuracy: 0.8883\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYXJfxLjnj7J",
    "outputId": "58dc3844-5b28-4b44-cbed-590746f7822b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33483272790908813"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pkIR8y_n8w4",
    "outputId": "23f1c8be-8941-4bd9-998b-1baf7d158de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883000016212463"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unZ1p7qtn-3B"
   },
   "source": [
    "# <mark>`Final Overview`</mark>\n",
    "  Tried many activation functions and optimizers with defferent learning rates..\n",
    "\n",
    "  * the best activation function is relu for hidden layers in all model archetecture.\n",
    "  * the best optimizers is Adam with learning rate 0.01 \n",
    "  * softmax activation function is use for multi-classes dataset\n",
    "  * Sigmoid activation function is use for binary classes dataset. (e.g 1 or 2, yes or no, apple or banana)\n",
    "  * Kernal_initializer == weight initializer in kera\n",
    "  * decay_steps == is warmup_steps\n",
    "  * decay_rate == warmup_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>`Callback to Control Training`</mark>\n",
    "> When you set your epochs to 10 and you desire accuracy is reached at epoch 6 so how can you stop your program? how to callback?\n",
    "\n",
    "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgwhnW9mbMOO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('loss')<0.4):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Building an Artificial Neural Network(classification).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
