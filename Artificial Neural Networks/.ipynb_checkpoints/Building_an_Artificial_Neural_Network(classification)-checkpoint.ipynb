{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "5pdfkELO-B4B"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pOds9zfkAuHM",
    "outputId": "6b739b7e-1029-4060-db59-317ba298fc32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ozQ7pMhYAwkD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNKcbM8eD9u5"
   },
   "source": [
    "# <mark>Data Preprocessing</mark>\n",
    "\n",
    "**<mark>Loading data   </mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PqVmLeuYFGG4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 5us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 61s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_xbjkKEFP1w"
   },
   "source": [
    "<mark>**Normalizing the images**</mark>\n",
    "\n",
    "we divide each and every pixel of the image in the trianing and testing sets by the maximum number of pixels (255)\r\n",
    "In this way each pixel will be in the range[0,1], Ny normalizing images we make sure that our model (ANN) trains faster\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M7XrSfwkFji3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_BSPws-DIeu3"
   },
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzG9qtn5S6cH",
    "outputId": "c5bf0cef-745e-4f4c-a60c-0259dfde614d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GIl5uFyIjfG"
   },
   "source": [
    "## <mark>Reshaping the data</mark>\n",
    "\n",
    "we are working on building a fully connected neural network, for that we reshape the training and test into vector form..\r\n",
    "\n",
    "vector ---> flate \n",
    "\n",
    "\n",
    "\n",
    "tensor ---> X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l4nTfQJYIm_H"
   },
   "outputs": [],
   "source": [
    "# you can see that our datasets are 28*28 dimensions..\n",
    "# we will reshape and flatten the images of dataset\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "\n",
    "# you can see that our images is 28*28 so we multiply X-axis and y-axis of the images to flatten the images of dataset\n",
    "# and -1 means all images... meaning convert nth number of image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOQwcovGSyGZ",
    "outputId": "917b48c6-37c5-4a4a-d96b-acce0cb3f221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D6azateDT4ru"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6BEjcWbT_Ad",
    "outputId": "9feb029c-d665-4e13-f4c5-90e7b581b607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAXk23bvTk8u"
   },
   "source": [
    "**See in the above cells that our all images of the dataset are now flatten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQK0TQoyWhuF"
   },
   "source": [
    "# <mark>Building Artificial Neural Network</mark>\n",
    "**Defining the Model**\n",
    "\n",
    "Simply define an object of the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "XGs5qwMSWpgt"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OA8galWSXGKF"
   },
   "source": [
    "**Adding a fully-connected Hidden layer**\n",
    "layer hyperparameter:\r\n",
    "  * number of neurons/units : 128\n",
    "  * activation function : ReLU\n",
    "  * input_shape: (784, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Tus_OAvDXoQE"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_uniform', input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q3JyNPRRhY9"
   },
   "source": [
    "**Adding PReLU Acitivation function to the archetecture of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IrWoDP94Q31l"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.PReLU(alpha_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBLyZ7uMTHWT"
   },
   "source": [
    "**with tanh activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "KZ7QTkeJOqyW"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=64, activation='tanh', input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "lpkApvbWTFnz"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=64, activation='relu',  input_shape=(784, ))) \n",
    "# # we can initialize weight by kernel_initializer='he_uniform',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTbDdbuvVGC0"
   },
   "source": [
    "**Defining Leaky_relu activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "73PdUMsQTod7"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# leaky_relu = LeakyReLU(alpha=0.01)\r\n",
    "# model.add(tf.keras.layers.Dense(units=64, activation=leaky_relu, input_shape=(784, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "hTopgFuOPQUI"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=32, activation='relu',  input_shape=(784, )))\n",
    "\n",
    "# # we can also initialize weight by kernel_initializer='he_uniform',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-DF6G0sX8zM"
   },
   "source": [
    "**Adding a Second layer with Dropout**\n",
    ">Dropout is a Regularization technique where we randomly set neurons in a layer to zero. That way while training those neurons won't be uploaded. Because some percentage od neurons won't be updated the whole training process is long and we have less chance for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "PsmAw_vJY9Vb"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C1WZf36ZyZr"
   },
   "source": [
    "**Adding the output layer**\n",
    "  * units number of classes (10 in the Fashion MNIST dataset)\n",
    "  * activation: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "6eb_RjDHaL9B"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZznSG0egTTra"
   },
   "source": [
    "**Output layer with Sigmoid activation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "uEz1PQ7CS4YE"
   },
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.Dense(units=10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "incyYb3raYrq"
   },
   "source": [
    "**Compiling the model**\n",
    "  * Optimizer: Adam\r\n",
    "  * Loss : Sparse softmax (categorical) crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up intilial_learning_rate, total_steps/decay_steps, decay_rate/warmup_learning_rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'total_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-359b2d397a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtotal_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minitial_learning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdecay_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     decay_rate=0.0001)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'total_steps'"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiHFXsqXXUMo"
   },
   "source": [
    "**Setting up Learning rate of optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "0z0ShBgJa5bR"
   },
   "outputs": [],
   "source": [
    "# defining Learning rate for adam optimizer\n",
    "\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,  loss='sparse_categorical_crossentropy', metrics='sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb9UWX-bZRPn"
   },
   "source": [
    "**Trying SGD (Stochostic Gradient Descent) optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "pbOdJRWhZZeG"
   },
   "outputs": [],
   "source": [
    "# Defining SGD Optimizer and assigining Learning_rate\n",
    "# from keras.optimizers import SGD\r\n",
    "\n",
    "# # decay=0.01\n",
    "# # With learning rate decay, the learning rate is calculated each update (e.g. end of each mini-batch) as follows:\n",
    "# # lrate = initial_lrate * (1 / (1 + decay * iteration))\n",
    "\n",
    "# opt = SGD(lr=0.01, momentum=0.9, decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtnL9xbhjo_s"
   },
   "source": [
    "**Checking the Artichecture of our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZPpe10cjlt-",
    "outputId": "e18521a3-784d-4169-f61c-7bd7ca94f83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0Mo9QMXjnXk"
   },
   "source": [
    "**<mark>Train the model</mark>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_ufEr1bkeCz",
    "outputId": "f3d1628a-319e-4fcd-bd6d-27b43f8f4d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 2s 831us/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9276\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.1789 - sparse_categorical_accuracy: 0.9310\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1821 - sparse_categorical_accuracy: 0.9307\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1784 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9311\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9321\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9346\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.1761 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9321\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1685 - sparse_categorical_accuracy: 0.9362\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9317\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9376\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 2s 848us/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9361\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 2s 839us/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9369\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 837us/step - loss: 0.1653 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 2s 876us/step - loss: 0.1630 - sparse_categorical_accuracy: 0.9369\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9368\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 0.1632 - sparse_categorical_accuracy: 0.9368\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.1587 - sparse_categorical_accuracy: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236735aebe0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0mKBg9WleOi",
    "outputId": "3213625b-a376-4cd7-d801-b139138eb19c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGWJSe3kl7SS"
   },
   "source": [
    "**Model evaluation and prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91sX9jNNmQ36",
    "outputId": "50c48d79-9fd2-4c68-d943-9202a7c16c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 764us/step - loss: 0.4829 - sparse_categorical_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYXJfxLjnj7J",
    "outputId": "58dc3844-5b28-4b44-cbed-590746f7822b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4828944206237793"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pkIR8y_n8w4",
    "outputId": "23f1c8be-8941-4bd9-998b-1baf7d158de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8374999761581421"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unZ1p7qtn-3B"
   },
   "source": [
    "# <mark>Final Overview</mark>\n",
    "  Tried many activation functions and optimizers with defferent learning rates..\n",
    "\r\n",
    "  * the best activation function is relu for hidden layers in all model archetecture.\n",
    "  * the best optimizers is Adam with learning rate 0.01 \n",
    "  * softmax activation function is use for multi-classes dataset\n",
    "  * Sigmoid activation function is use for binary classes dataset. (e.g 1 or 2, yes or no, apple or banana)\n",
    "  * Kernal_initializer == weight initializer in kera\n",
    "  * s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "QgwhnW9mbMOO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Building an Artificial Neural Network(classification).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
